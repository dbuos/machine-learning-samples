{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of a plain RNN basic operations equivalent to Pytorch RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "rnn = nn.RNN(input_size=4, hidden_size=8, num_layers=1, nonlinearity='relu')\n",
    "input = torch.rand(size=(5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight input-hidden torch.Size([8, 4])\n",
      "Weight hidden-hidden torch.Size([8, 8])\n",
      "Bias input-hidden torch.Size([8])\n",
      "Bias hidden-hidden torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print('Weight input-hidden', rnn.weight_ih_l0.shape)\n",
    "print('Weight hidden-hidden', rnn.weight_hh_l0.shape)\n",
    "print('Bias input-hidden', rnn.bias_ih_l0.shape)\n",
    "print('Bias hidden-hidden', rnn.bias_hh_l0.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output calculation\n",
    "last_h is the last hidden state of the RNN. It is the same that the last element of the hidden_states list (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2044, 0.3398, 0.1788, 0.0464, 0.5647, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, last_h = rnn(input)\n",
    "last_h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classic calculation (Pytorch way)\n",
    "It uses 2 matrices: one for the input and one for the hidden state. The output is the activation of the sum of the bias plus matrix multiplication of the input and the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2044, 0.3398, 0.1788, 0.0464, 0.5647, 0.0000, 0.0000, 0.0000],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden state is the same:  True\n"
     ]
    }
   ],
   "source": [
    "last_hidden = torch.zeros((8,))\n",
    "\n",
    "for i in range(input.shape[0]):\n",
    "    ih = torch.matmul(input[i], rnn.weight_ih_l0.T)\n",
    "    hh = torch.matmul(last_hidden, rnn.weight_hh_l0.T)\n",
    "\n",
    "    ih = ih + rnn.bias_ih_l0\n",
    "    hh = hh + rnn.bias_hh_l0\n",
    "\n",
    "    h0 = torch.relu(ih + hh)\n",
    "    last_hidden = h0 \n",
    "\n",
    "display(last_hidden)   \n",
    "print(\"Final hidden state is the same: \", torch.allclose(last_hidden, last_h.squeeze()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternative calculation (One single matrix)\n",
    "\n",
    "It uses a single matrix to calculate the output. The matrix is the concatenation of the input and hidden state matrices. The output is the activation of the sum of the bias plus matrix multiplication of the input and the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2044, 0.3398, 0.1788, 0.0464, 0.5647, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden state is the same:  True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "single_weight_matrix = torch.cat([rnn.weight_ih_l0, rnn.weight_hh_l0], dim=1)\n",
    "all_b = rnn.bias_ih_l0 + rnn.bias_hh_l0\n",
    "last_hidden_single = torch.zeros((8,))\n",
    "\n",
    "for i in range(input.shape[0]):\n",
    "    input_i = torch.cat([input[i].reshape(1, 4), last_hidden_single.reshape(1, 8)], dim=1)\n",
    "    ih = torch.matmul(input_i, single_weight_matrix.T)\n",
    "    h0 = torch.relu(ih + all_b)\n",
    "    last_hidden_single = h0 \n",
    "\n",
    "display(last_hidden_single)\n",
    "print(\"Final hidden state is the same: \", torch.allclose(last_hidden_single, last_h.squeeze()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch_1.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e36ad36b4333c4784ff83102b792e06f84ced839eab6a45eaa744acd129fd3d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
