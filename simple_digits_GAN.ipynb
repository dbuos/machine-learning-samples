{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple example of trainning a GAN for digits image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = nn.Sequential()\n",
    "        self.generator.add_module('ln1', nn.Linear(in_features=20, out_features=100, bias=False))\n",
    "        self.generator.add_module('ln1_LRelu', nn.LeakyReLU())\n",
    "\n",
    "        self.generator.add_module('ln2', nn.Linear(in_features=100, out_features=100, bias=False))\n",
    "        self.generator.add_module('ln2_LRelu', nn.LeakyReLU())\n",
    "\n",
    "        self.generator.add_module('ln2', nn.Linear(in_features=100, out_features=784))\n",
    "        self.generator.add_module('ln2_Tahn', nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.generator(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        # self.model.add_module('flatt0', nn.Flatten())\n",
    "\n",
    "        self.model.add_module('ln1', nn.Linear(in_features=784, out_features=100, bias=False))\n",
    "        self.model.add_module('ln1_LRelu', nn.LeakyReLU())\n",
    "        self.model.add_module('drop1', nn.Dropout(p=0.5))\n",
    "\n",
    "        self.model.add_module('ln2', nn.Linear(in_features=100, out_features=100, bias=False))\n",
    "        self.model.add_module('ln2_LRelu', nn.LeakyReLU())\n",
    "        self.model.add_module('drop2', nn.Dropout(p=0.5))\n",
    "\n",
    "        self.model.add_module('ln2', nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "discr = Discriminator()\n",
    "\n",
    "latent_vect = torch.normal(0, 1, (1, 20))\n",
    "\n",
    "imgs_batch = generator(latent_vect).view(1, 784)\n",
    "discr(imgs_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (generator): Sequential(\n",
      "    (ln1): Linear(in_features=20, out_features=100, bias=True)\n",
      "    (ln1_LRelu): LeakyReLU(negative_slope=0.01)\n",
      "    (ln2): Linear(in_features=100, out_features=784, bias=True)\n",
      "    (ln2_Tahn): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (ln1): Linear(in_features=784, out_features=100, bias=False)\n",
      "    (ln1_LRelu): LeakyReLU(negative_slope=0.01)\n",
      "    (drop1): Dropout(p=0.5, inplace=False)\n",
      "    (ln2): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(discr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(-1.), torch.Size([1, 28, 28]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(std=(0.5), mean=(0.5))\n",
    "])\n",
    "\n",
    "root_data = \"./data/mnist/train\"\n",
    "dataset = torchvision.datasets.MNIST(root=root_data, train=True, transform=transform, download=True)\n",
    "\n",
    "img, label = dataset[0]\n",
    "torch.max(img), torch.min(img), img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_noise(batch_size, size):\n",
    "    return torch.randn(batch_size, size)\n",
    "\n",
    "create_noise(10, 20).shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_s = 128\n",
    "train_ds = DataLoader(dataset, batch_size=batch_s, shuffle=False, num_workers=20)\n",
    "\n",
    "input_real, label_real = next(iter(train_ds))\n",
    "input_real = input_real.view(batch_s, -1)\n",
    "input_z = create_noise(batch_s, 20)\n",
    "print(input_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen out shape: torch.Size([128, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1]), torch.Size([128, 1]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_out = generator(input_z)\n",
    "print('Gen out shape:', g_out.shape)\n",
    "\n",
    "fake_probs = discr(g_out)\n",
    "real_probs = discr(input_real)\n",
    "\n",
    "fake_probs.shape, real_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.mime import image\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "d_optim = torch.optim.AdamW(params=discr.parameters())\n",
    "g_optim = torch.optim.AdamW(params=generator.parameters())\n",
    "\n",
    "discr.to(device)\n",
    "generator.to(device)\n",
    "\n",
    "def train_disc(x):\n",
    "    discr.zero_grad()\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(batch_size, -1).to(device)\n",
    "\n",
    "    #Train on real Images\n",
    "    labels_real = torch.ones((batch_size, 1), device=device)\n",
    "    prob_real = discr(x)\n",
    "    loss_real = loss_fn(prob_real, labels_real)\n",
    "\n",
    "    #Train on fake images\n",
    "    input_z = create_noise(batch_size, 20).to(device)\n",
    "    fake_images = generator(input_z)\n",
    "    labels_fake = torch.zeros((batch_size,1), device=device)\n",
    "    prob_fake = discr(fake_images)\n",
    "    loss_fake = loss_fn(prob_fake, labels_fake)\n",
    "\n",
    "    loss = loss_fake + loss_real\n",
    "    loss.backward()\n",
    "    d_optim.step()\n",
    "    return loss.data.item(), prob_real.detach(), prob_fake.detach()\n",
    "\n",
    "def train_gen(x):\n",
    "    generator.zero_grad()\n",
    "    batch_size = x.size(0)\n",
    "\n",
    "    input_z = create_noise(batch_size, 20).to(device)\n",
    "    labels_real = torch.ones((batch_size, 1), device=device)\n",
    "    fake_images = generator(input_z)\n",
    "    prob_fake = discr(fake_images)\n",
    "    loss = loss_fn(prob_fake, labels_real)\n",
    "\n",
    "    loss.backward()\n",
    "    g_optim.step()\n",
    "\n",
    "    return loss.data.item()\n",
    "\n",
    "fixed_z = create_noise(batch_s, 20).to(device)\n",
    "def create_samples():\n",
    "    images = generator(fixed_z).reshape((batch_s, 1, 28,28))\n",
    "    return (images+1)/2.0    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, lb = next(iter(train_ds))\n",
    "imgs = imgs.view(32, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0594489574432373"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_disc(imgs)\n",
    "train_gen(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_samples().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def train(num_epoch = 100):\n",
    "    epoch_samples = []\n",
    "    dis_losses = []\n",
    "    gen_losses = []\n",
    "    d_real = []\n",
    "    d_fake = []\n",
    "\n",
    "    progress_bar = tqdm(range(num_epoch*len(train_ds)))\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        d_loss, g_loss = [], []\n",
    "        real, fake = [], []\n",
    "        discr.train()\n",
    "        generator.train()\n",
    "        for x, _ in train_ds:\n",
    "            dd_loss, dd_real, dd_fake = train_disc(x)\n",
    "            gg_loss = train_gen(x)\n",
    "\n",
    "            d_loss.append(dd_loss)\n",
    "            g_loss.append(gg_loss)\n",
    "\n",
    "            real.append(torch.sigmoid(dd_real).mean().cpu())\n",
    "            fake.append(torch.sigmoid(dd_fake).mean().cpu())\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        dis_losses.append(torch.tensor(d_loss).mean())  \n",
    "        gen_losses.append(torch.tensor(g_loss).mean())\n",
    "        d_real.append(torch.tensor(real).mean())\n",
    "        d_fake.append(torch.tensor(fake).mean()) \n",
    "\n",
    "        print(f'Epoch {epoch}') \n",
    "        print(f'Losses -> Gen: {g_loss[-1]:.4f}, Dis: {d_loss[-1]:.4f}') \n",
    "\n",
    "        epoch_samples.append(create_samples().detach().cpu().numpy())\n",
    "    return epoch_samples, real, fake    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d4e0e5ad934758ae72304f4d23fbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Losses -> Gen: 0.7070, Dis: 1.0772\n",
      "Epoch 1\n",
      "Losses -> Gen: 0.6988, Dis: 1.0409\n",
      "Epoch 2\n",
      "Losses -> Gen: 0.7106, Dis: 1.0581\n",
      "Epoch 3\n",
      "Losses -> Gen: 0.7061, Dis: 1.1108\n",
      "Epoch 4\n",
      "Losses -> Gen: 0.7083, Dis: 1.0659\n",
      "Epoch 5\n",
      "Losses -> Gen: 0.6973, Dis: 1.1200\n",
      "Epoch 6\n",
      "Losses -> Gen: 0.7020, Dis: 1.0795\n",
      "Epoch 7\n",
      "Losses -> Gen: 0.7053, Dis: 1.1121\n",
      "Epoch 8\n",
      "Losses -> Gen: 0.7068, Dis: 0.9716\n",
      "Epoch 9\n",
      "Losses -> Gen: 0.6972, Dis: 1.0376\n",
      "Epoch 10\n",
      "Losses -> Gen: 0.7103, Dis: 1.0658\n",
      "Epoch 11\n",
      "Losses -> Gen: 0.6909, Dis: 1.0285\n",
      "Epoch 12\n",
      "Losses -> Gen: 0.7087, Dis: 1.0312\n",
      "Epoch 13\n",
      "Losses -> Gen: 0.7118, Dis: 0.9938\n",
      "Epoch 14\n",
      "Losses -> Gen: 0.7059, Dis: 1.0381\n",
      "Epoch 15\n",
      "Losses -> Gen: 0.7000, Dis: 1.0623\n",
      "Epoch 16\n",
      "Losses -> Gen: 0.6978, Dis: 1.0797\n",
      "Epoch 17\n",
      "Losses -> Gen: 0.7084, Dis: 1.1194\n",
      "Epoch 18\n",
      "Losses -> Gen: 0.7092, Dis: 1.1198\n",
      "Epoch 19\n",
      "Losses -> Gen: 0.7028, Dis: 1.0165\n",
      "Epoch 20\n",
      "Losses -> Gen: 0.7078, Dis: 1.0539\n",
      "Epoch 21\n",
      "Losses -> Gen: 0.7024, Dis: 1.0484\n",
      "Epoch 22\n",
      "Losses -> Gen: 0.7105, Dis: 1.0583\n",
      "Epoch 23\n",
      "Losses -> Gen: 0.7090, Dis: 1.0736\n",
      "Epoch 24\n",
      "Losses -> Gen: 0.7108, Dis: 0.9796\n",
      "Epoch 25\n",
      "Losses -> Gen: 0.6985, Dis: 1.0587\n",
      "Epoch 26\n",
      "Losses -> Gen: 0.7071, Dis: 1.0809\n",
      "Epoch 27\n",
      "Losses -> Gen: 0.7084, Dis: 1.0787\n",
      "Epoch 28\n",
      "Losses -> Gen: 0.7103, Dis: 1.0529\n",
      "Epoch 29\n",
      "Losses -> Gen: 0.7085, Dis: 1.1539\n",
      "Epoch 30\n",
      "Losses -> Gen: 0.7033, Dis: 1.0544\n",
      "Epoch 31\n",
      "Losses -> Gen: 0.7076, Dis: 1.1210\n",
      "Epoch 32\n",
      "Losses -> Gen: 0.7067, Dis: 1.1051\n",
      "Epoch 33\n",
      "Losses -> Gen: 0.7059, Dis: 1.0382\n",
      "Epoch 34\n",
      "Losses -> Gen: 0.6926, Dis: 1.0824\n",
      "Epoch 35\n",
      "Losses -> Gen: 0.6985, Dis: 1.1256\n",
      "Epoch 36\n",
      "Losses -> Gen: 0.7050, Dis: 1.0663\n",
      "Epoch 37\n",
      "Losses -> Gen: 0.7064, Dis: 1.0848\n",
      "Epoch 38\n",
      "Losses -> Gen: 0.7078, Dis: 1.1403\n",
      "Epoch 39\n",
      "Losses -> Gen: 0.7077, Dis: 1.0957\n",
      "Epoch 40\n",
      "Losses -> Gen: 0.7036, Dis: 1.0715\n",
      "Epoch 41\n",
      "Losses -> Gen: 0.7064, Dis: 1.1421\n",
      "Epoch 42\n",
      "Losses -> Gen: 0.7076, Dis: 1.0902\n",
      "Epoch 43\n",
      "Losses -> Gen: 0.7015, Dis: 1.1232\n",
      "Epoch 44\n",
      "Losses -> Gen: 0.7052, Dis: 1.0683\n",
      "Epoch 45\n",
      "Losses -> Gen: 0.7086, Dis: 1.0837\n",
      "Epoch 46\n",
      "Losses -> Gen: 0.6857, Dis: 1.1011\n",
      "Epoch 47\n",
      "Losses -> Gen: 0.7022, Dis: 1.0730\n",
      "Epoch 48\n",
      "Losses -> Gen: 0.7064, Dis: 1.1019\n",
      "Epoch 49\n",
      "Losses -> Gen: 0.7093, Dis: 1.0900\n"
     ]
    }
   ],
   "source": [
    "results = train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "samples = results[0]\n",
    "plt.imshow(samples[30][2].reshape(28,28), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(discr)\n",
    "print(generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cdbf094c3e2d11b30478a1f6f10290d4ee78e6b46f57992373b88ecd109df83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
