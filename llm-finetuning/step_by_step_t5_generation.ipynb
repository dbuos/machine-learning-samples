{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Summarization with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "data_2 = load_dataset(\"knkarthick/dialogsum\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T23:10:20.403505207Z",
     "start_time": "2023-07-03T23:10:17.010840296Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"google/flan-t5-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from transformers.generation.stopping_criteria import MaxLengthCriteria\n",
    "\n",
    "def greedy_search(attention_mask, encoder_outputs, max_new_tokens=50, batch_size=1):\n",
    "    eos_token_id = model.generation_config.eos_token_id\n",
    "    decoder_start_token_id = 0\n",
    "    input_ids = torch.ones((batch_size, 1), dtype=torch.long, device=device) * decoder_start_token_id\n",
    "    max_length = max_new_tokens + input_ids.shape[-1]\n",
    "\n",
    "    stopping_criteria = MaxLengthCriteria(max_length=max_length)\n",
    "    eos_token_id_tensor = torch.tensor([eos_token_id]).to(input_ids.device)\n",
    "    generating = True\n",
    "    past_key_values = None\n",
    "\n",
    "    while generating:\n",
    "        outputs = model(\n",
    "            decoder_input_ids=input_ids[:, -1:],\n",
    "            past_key_values=past_key_values,\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            attention_mask=attention_mask,\n",
    "            use_cache=True,\n",
    "            return_dict=True,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "        )\n",
    "\n",
    "        next_tokens = torch.argmax(outputs.logits[:, -1, :], dim=-1)\n",
    "        past_key_values = outputs.past_key_values\n",
    "\n",
    "        input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
    "        generating = not (next_tokens.eq(eos_token_id_tensor).any() or stopping_criteria(input_ids, None))\n",
    "\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "def do_generate(inputs_from_tokenizer):\n",
    "    #First, we need to use the encoder model\n",
    "    encoder_outputs = model.get_encoder()(\n",
    "        input_ids=inputs_from_tokenizer[\"input_ids\"],\n",
    "        attention_mask=inputs_from_tokenizer[\"attention_mask\"],\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        return_dict=True\n",
    "    )\n",
    "\n",
    "    #Use the decoder model to generate the output sequence\n",
    "    result_tokens = greedy_search(\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        encoder_outputs=encoder_outputs\n",
    "    )\n",
    "\n",
    "    return result_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T23:10:35.781380541Z",
     "start_time": "2023-07-03T23:10:35.740442216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "summarize: \n",
      "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
      "#Person2#: I found it would be a good idea to get a check-up.\n",
      "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
      "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
      "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
      "#Person2#: Ok.\n",
      "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
      "#Person2#: Yes.\n",
      "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
      "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
      "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
      "#Person2#: Ok, thanks doctor.\n",
      "Generation:\n",
      "Person2 is here for a check-up. He hasn't had one in 5 years. He smokes. He's trying to quit.\n",
      "\n",
      "\n",
      "Text:\n",
      "summarize: \n",
      "#Person1#: Hello Mrs. Parker, how have you been?\n",
      "#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\n",
      "#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\n",
      "#Person2#: What about Rubella and Mumps?\n",
      "#Person1#: Well, I can only give him these for now, and after a couple of weeks I can administer the rest.\n",
      "#Person2#: OK, great. Doctor, I think I also may need a Tetanus booster. Last time I got it was maybe fifteen years ago!\n",
      "#Person1#: We will check our records and I'll have the nurse administer and the booster as well. Now, please hold Ricky's arm tight, this may sting a little.\n",
      "Generation:\n",
      "Ricky is coming for his vaccinations.\n",
      "\n",
      "\n",
      "Text:\n",
      "summarize: \n",
      "#Person1#: Excuse me, did you see a set of keys?\n",
      "#Person2#: What kind of keys?\n",
      "#Person1#: Five keys and a small foot ornament.\n",
      "#Person2#: What a shame! I didn't see them.\n",
      "#Person1#: Well, can you help me look for it? That's my first time here.\n",
      "#Person2#: Sure. It's my pleasure. I'd like to help you look for the missing keys.\n",
      "#Person1#: It's very kind of you.\n",
      "#Person2#: It's not a big deal.Hey, I found them.\n",
      "#Person1#: Oh, thank God! I don't know how to thank you, guys.\n",
      "#Person2#: You're welcome.\n",
      "Generation:\n",
      "Person2 found five keys and a small ornament missing from Person1's house.\n",
      "\n",
      "\n",
      "Text:\n",
      "summarize: \n",
      "#Person1#: Are you still watching the soap opera, Nancy?\n",
      "#Person2#: Yeah. I can't take my eyes off that when it is on.\n",
      "#Person1#: Is it that appealing?\n",
      "#Person2#: Well, the cast of the opera isn't very strong and the story isn't so impressive, but the main actor's acting is really outstanding, who is handsome, too.\n",
      "#Person1#: Shall we think you need a break right now? There is a football match on channel eight.\n",
      "#Person2#: Oh, stop talking about that stupid match. I really don't understand why certain people are running after one ball.\n",
      "#Person1#: If we can choose program, I'd rather watch the documentary, this kind of soap opera is really boring.\n",
      "#Person2#: Everyone has his own taste. And have you ever heard of the saying, 'One man's meat is another's poison.'\n",
      "#Person1#: But you been in front of TV for almost 5 hours, even at dinner time. I had to say you were the most selfish person I have ever seen.\n",
      "#Person2#: Well, well, watch channel.\n",
      "Generation:\n",
      "Person1 is watching a soap opera. Person2 is watching a football match.\n",
      "\n",
      "\n",
      "Text:\n",
      "summarize: \n",
      "#Person1#: You have the right to remain silent. Anything you say can and will be used against you in a court of law. You have the right to have an attorney present during questioning. If you cannot afford an attorney, one will be appointed for you. Do you understand?\n",
      "#Person2#: Yes.\n",
      "#Person1#: What's your name?\n",
      "#Person2#: My name is James.\n",
      "#Person1#: What's your nationality?\n",
      "#Person2#: American.\n",
      "#Person1#: What's your relationship with the victim?\n",
      "#Person2#: I don't know him.\n",
      "#Person1#: Why did you attack the victim?\n",
      "#Person2#: Because he beat me first when I tried to stop him from grabbing my bag and running away.\n",
      "#Person1#: How many times did you stab the victim?\n",
      "#Person2#: I stabbed his belly three times.\n",
      "#Person1#: Did you know that your actions might cause serous injuries or death?\n",
      "#Person2#: I knew, but I couldn't control myself.\n",
      "#Person1#: Was it your intention to kill the victim?\n",
      "#Person2#: No. I didn't kill him on purpose, madam. It's him who caused the incident. I need to see my attorney.\n",
      "#Person1#: OK. Give me his number and we'll contact him.\n",
      "Generation:\n",
      "James attacked the victim because he beat him first. He stabbed his belly three times. He needs to see his attorney.\n",
      "\n",
      "\n",
      "Text:\n",
      "summarize: \n",
      "#Person1#: Jenny, are you having a good time?\n",
      "#Person2#: Yes, of course. This is a really wonderful party with interesting people and great food.\n",
      "#Person1#: I'm glad you are enjoying yourself.\n",
      "#Person2#: Thank you for the invitation.\n",
      "#Person1#: It's my pleasure. Can I get you another glass of champagne?\n",
      "#Person2#: Yes, I'd love another glass. You're a wonderful host. Thank you for everything.\n",
      "#Person1#: It's my pleasure having you here.\n",
      "Generation:\n",
      "Jenny is having a good time at the party.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0,1,2,45,50,60]:\n",
    "    print(\"Text:\")\n",
    "    text = \"summarize: \\n\" + data_2[\"train\"][i][\"dialogue\"]\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    generation = do_generate(inputs)\n",
    "    gen_text = tokenizer.batch_decode(generation, skip_special_tokens=True)\n",
    "    print(text)\n",
    "    print(\"Generation:\")\n",
    "    print(gen_text[0])\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T23:12:24.039790450Z",
     "start_time": "2023-07-03T23:12:22.633330440Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code2metrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1e69b0e984c216f4919daa85c71bc60c20715b9864642c2f5eda88c935825bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
