{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Simple CNN for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import ViTFeatureExtractor, AutoModelForImageClassification\n",
    "vit_model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=10);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from eurosat_dataset import load_eurosat_for_vit\n",
    "\n",
    "optimizer = AdamW(vit_model.parameters(), lr=5e-5)\n",
    "loaders = load_eurosat_for_vit(batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(loaders['train'])\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "vit_model.to(device)\n",
    "vit_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in loaders['train']:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        outputs = vit_model(pixel_values=x_batch, labels=y_batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model_vit(model, data_loader, device):   \n",
    "    model.eval()\n",
    "    y_list = []\n",
    "    pred_list = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        output = model(x_batch)\n",
    "        pred_list.append(torch.argmax(output['logits'], dim=1).cpu())\n",
    "        y_list.append(y_batch)\n",
    "    preds = torch.cat(pred_list, dim=0)\n",
    "    y_true = torch.cat(y_list, dim=0)    \n",
    "    #Calculate the accuracy\n",
    "    is_correct = (preds == y_true).float()\n",
    "    accuracy = is_correct.sum() / is_correct.numel()\n",
    "    print(f'Accuracy: {accuracy:4f}')\n",
    "    return accuracy\n",
    "\n",
    "evaluate_model_vit(vit_model, loaders['test'], device)    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mimetypes import init\n",
    "\n",
    "\n",
    "def create_model(img_channels = 3):\n",
    "    model = nn.Sequential()\n",
    "    model.add_module('conv0', nn.Conv2d(in_channels=img_channels, out_channels=16, kernel_size=5, padding='same'))\n",
    "    model.add_module('norm0', nn.BatchNorm2d(16))\n",
    "    model.add_module('relu0', nn.ReLU())\n",
    "    model.add_module('pool0', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    model.add_module('conv1', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding='same'))\n",
    "    model.add_module('norm1', nn.BatchNorm2d(32))\n",
    "    model.add_module('relu1', nn.ReLU())\n",
    "    model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same'))\n",
    "    model.add_module('norm2', nn.BatchNorm2d(64))\n",
    "    model.add_module('relu2', nn.ReLU())\n",
    "    model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    model.add_module('conv3', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding='same'))\n",
    "    model.add_module('norm3', nn.BatchNorm2d(128))\n",
    "    model.add_module('relu3', nn.ReLU())\n",
    "    model.add_module('pool3', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    model.add_module('conv4', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding='same'))\n",
    "    model.add_module('norm4', nn.BatchNorm2d(256))\n",
    "    model.add_module('relu4', nn.ReLU())\n",
    "    model.add_module('pool4', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    model.add_module('flatten', nn.Flatten())\n",
    "    model.add_module('dropout0', nn.Dropout(p=0.5))\n",
    "    model.add_module('ln0', nn.Linear(1024, out_features=512))\n",
    "    model.add_module('selu4', nn.SELU())\n",
    "    model.add_module('dropout1', nn.Dropout(p=0.5))\n",
    "    model.add_module('ln1', nn.Linear(512, out_features=10))\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "in_tensor = torch.randn(1, 3, 64, 64)\n",
    "create_model()(in_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and prepare an image dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "#Import image augmentation clases from torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize, RandomHorizontalFlip, RandomRotation, Resize\n",
    "from torch.utils.data import DataLoader\n",
    "image_path = './data/eurosat'\n",
    "transform = Compose([\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomRotation(degrees=10),\n",
    "    ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "eurosat_dataset = datasets.EuroSAT(root=image_path, transform=transform, download=True)\n",
    "\n",
    "#Randomize the dataset\n",
    "torch.manual_seed(1)\n",
    "train_len = int(0.85 * len(eurosat_dataset)) - int(0.85 * len(eurosat_dataset) * 0.2)\n",
    "valid_len = int(0.85 * len(eurosat_dataset) * 0.2)\n",
    "test_len = len(eurosat_dataset) - train_len - valid_len\n",
    "train_dataset, test_dataset, valid_dataset = torch.utils.data.random_split(eurosat_dataset, [train_len, valid_len, test_len])\n",
    "\n",
    "#Create DataLoaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=20)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=20)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the training loop function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, epochs, train_dl, valid_dl, gpu=False):\n",
    "    if gpu:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_hist_train = [0] * epochs\n",
    "    accuracy_hist_train = [0] * epochs\n",
    "\n",
    "    loss_hist_valid = [0] * epochs\n",
    "    accuracy_hist_valid = [0] * epochs\n",
    "    progress_bar = tqdm(range(epochs*len(train_dl)))\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            if gpu:\n",
    "                x_batch = x_batch.cuda()\n",
    "                y_batch = y_batch.cuda()\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            \n",
    "            loss.backward() #Calculate tensor gradients with backpropagation\n",
    "            optimizer.step() #Apply updates to weights using the optimizer gradient descent specif impl algorithm\n",
    "            optimizer.zero_grad() #Reset the gradients for the next iteration\n",
    "            \n",
    "            #Calculate and save matrics\n",
    "            loss_hist_train[epoch] += loss.item() * y_batch.size(0) #Add the loss to the loss history\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).cpu().float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        loss_hist_train[epoch] /= train_len\n",
    "        accuracy_hist_train[epoch] /= train_len\n",
    "\n",
    "        model.eval() #Set the model to evaluation mode\n",
    "        with torch.no_grad(): #Turn off gradients\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                if gpu:\n",
    "                    x_batch = x_batch.cuda()\n",
    "                    y_batch = y_batch.cuda()\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += (loss.item() * y_batch.size(0))\n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).cpu().float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "            loss_hist_valid[epoch] /= valid_len\n",
    "            accuracy_hist_valid[epoch] /= valid_len\n",
    "        print(f'Epoch {epoch+1}/{epochs} accuracy: {accuracy_hist_train[epoch]:4f} valid_accuracy: {accuracy_hist_valid[epoch]:4f}')\n",
    "    return loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, gpu=False):\n",
    "    if gpu:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()    \n",
    "    model.eval()\n",
    "    y_list = []\n",
    "    pred_list = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        if gpu:\n",
    "            x_batch = x_batch.cuda()\n",
    "        pred = model(x_batch)\n",
    "        pred_list.append(torch.argmax(pred, dim=1).cpu())\n",
    "        y_list.append(y_batch)\n",
    "    preds = torch.cat(pred_list, dim=0)\n",
    "    y_true = torch.cat(y_list, dim=0)    \n",
    "    #Calculate the accuracy\n",
    "    is_correct = (preds == y_true).float()\n",
    "    accuracy = is_correct.sum() / is_correct.numel()\n",
    "    print(f'Accuracy: {accuracy:4f}')\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpu_model = create_model()\n",
    "\n",
    "#Measure the time it takes to train the model\n",
    "import time\n",
    "start = time.time()\n",
    "loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid = train(gpu_model, epochs=40, train_dl=train_loader, valid_dl=valid_loader, gpu=True)\n",
    "end = time.time()\n",
    "print(f'Time to train: {end-start}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cpu_model = create_model()\n",
    "\n",
    "#Measure the time it takes to train the model\n",
    "import time\n",
    "start = time.time()\n",
    "loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid = train(cpu_model, epochs=15, train_dl=train_loader, valid_dl=valid_loader, gpu=False)\n",
    "end = time.time()\n",
    "print(f'Time to train: {end-start}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plot the loss\n",
    "plt.plot(loss_hist_train, label='Training Loss')\n",
    "plt.plot(loss_hist_valid, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(gpu_model, test_loader, gpu=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(cpu_model, test_loader, gpu=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "class ClsModel(pl.LightningModule):\n",
    "    def __init__(self, img_channels=3) -> None:\n",
    "        super().__init__()\n",
    "        model = nn.Sequential()\n",
    "        model.add_module('conv0', nn.Conv2d(in_channels=img_channels, out_channels=16, kernel_size=5, padding='same'))\n",
    "        model.add_module('relu0', nn.ReLU())\n",
    "        model.add_module('pool0', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        model.add_module('conv1', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding='same'))\n",
    "        model.add_module('relu1', nn.ReLU())\n",
    "        model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same'))\n",
    "        model.add_module('relu2', nn.ReLU())\n",
    "        model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
    "        \n",
    "\n",
    "        model.add_module('flatten', nn.Flatten())\n",
    "        model.add_module('ln0', nn.Linear(4096, out_features=1024))\n",
    "        model.add_module('relu4', nn.ReLU())\n",
    "        model.add_module('ln1', nn.Linear(1024, out_features=10))\n",
    "        self.model = model\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def step(self, batch):\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        return loss_fn(y_pred, y)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss = self.step(train_batch)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss  \n",
    "\n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        loss = self.step(valid_batch)\n",
    "        self.log('valid_loss', loss)\n",
    "        return loss       \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lmodel = ClsModel()\n",
    "trainer = pl.Trainer(max_epochs=20, accelerator='gpu', devices=1)\n",
    "\n",
    "start = time.time()\n",
    "trainer.fit(lmodel, train_loader, valid_loader)\n",
    "end = time.time()\n",
    "print(f'Time to train: {end-start}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(lmodel, test_loader, gpu=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cdbf094c3e2d11b30478a1f6f10290d4ee78e6b46f57992373b88ecd109df83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}