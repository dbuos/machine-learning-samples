{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple CNN for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.vit.modeling_vit.ViTModel"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify model is instance of nn.Module\n",
    "isinstance(model, nn.Module)\n",
    "vit_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_channels = 3):\n",
    "    model = nn.Sequential()\n",
    "    # model.add_module('conv0', nn.Conv2d(in_channels=img_channels, out_channels=16, kernel_size=5, padding='same'))\n",
    "    # model.add_module('relu0', nn.ReLU())\n",
    "    # model.add_module('pool0', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    # model.add_module('conv1', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding='same'))\n",
    "    # model.add_module('relu1', nn.ReLU())\n",
    "    # model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    # model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same'))\n",
    "    # model.add_module('relu2', nn.ReLU())\n",
    "    # model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    # model.add_module('conv3', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding='same'))\n",
    "    # model.add_module('relu3', nn.ReLU())\n",
    "    # model.add_module('pool3', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    # model.add_module('conv4', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding='same'))\n",
    "    # model.add_module('relu4', nn.ReLU())\n",
    "    # model.add_module('pool4', nn.MaxPool2d(kernel_size=2))\n",
    "    model.add_module('vit', vit_model)\n",
    "    # model.add_module('flatten', nn.Flatten())\n",
    "    # model.add_module('dropout0', nn.Dropout(p=0.5))\n",
    "    # model.add_module('ln0', nn.Linear(1024, out_features=512))\n",
    "    # model.add_module('relu4', nn.ReLU())\n",
    "    # model.add_module('dropout1', nn.Dropout(p=0.5))\n",
    "    # model.add_module('ln1', nn.Linear(512, out_features=10))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.2690,  0.1126,  0.0388,  ..., -0.0805, -0.0961, -0.0967],\n",
       "         [ 0.0750, -0.0898,  0.0955,  ...,  0.1092, -0.0312, -0.1363],\n",
       "         [ 0.2899, -0.0878, -0.0245,  ...,  0.0303,  0.0224, -0.0342],\n",
       "         ...,\n",
       "         [ 0.4162,  0.0329, -0.1779,  ...,  0.1251,  0.0237, -0.2066],\n",
       "         [ 0.2597,  0.0466, -0.1116,  ...,  0.0249, -0.0543, -0.1122],\n",
       "         [ 0.1294,  0.0503,  0.0673,  ...,  0.0747, -0.0468, -0.0782]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2760,  0.0227, -0.5505,  0.1537, -0.0372,  0.6907,  0.1118,  0.2593,\n",
       "         -0.4370,  0.1347, -0.2891,  0.6998, -0.4056,  0.3344, -0.3234,  0.6861,\n",
       "         -0.7918,  0.0525, -0.1030,  0.0709,  0.5463, -0.7283, -0.0366, -0.5570,\n",
       "          0.8518,  0.2218, -0.5922, -0.4778,  0.2425,  0.1889,  0.1958,  0.6503,\n",
       "         -0.1981,  0.3196,  0.5965,  0.1285, -0.0282, -0.0061,  0.4933, -0.3511,\n",
       "         -0.4261, -0.3544,  0.3496, -0.0520, -0.1800,  0.0146,  0.4244,  0.3339,\n",
       "          0.3204,  0.1872, -0.5298,  0.5569,  0.3111,  0.4003, -0.3310,  0.6776,\n",
       "          0.1944, -0.3722, -0.5272,  0.1869,  0.1472, -0.7495, -0.4493,  0.0041,\n",
       "         -0.4447,  0.1000,  0.4525,  0.7084, -0.0637, -0.2768, -0.8335, -0.2246,\n",
       "          0.5482,  0.4630, -0.2930,  0.2838,  0.6646,  0.4983,  0.6935, -0.2329,\n",
       "         -0.2727,  0.1147, -0.5085,  0.3464, -0.5270,  0.6221,  0.5962, -0.0724,\n",
       "          0.7914,  0.1668, -0.0072, -0.3113, -0.0423, -0.4606,  0.0759,  0.4579,\n",
       "          0.4316, -0.4044, -0.6681,  0.0834,  0.0788,  0.2056, -0.5726, -0.5251,\n",
       "          0.3162, -0.6954, -0.7177,  0.5873,  0.1710, -0.7712,  0.0650, -0.0895,\n",
       "         -0.6575, -0.0489, -0.1990,  0.1950, -0.6059, -0.5125,  0.1361, -0.2935,\n",
       "         -0.0133,  0.4636, -0.2576,  0.3971, -0.3479,  0.5323, -0.0181, -0.2500,\n",
       "          0.6927, -0.4155, -0.3316, -0.2829, -0.1589,  0.5578, -0.6147,  0.5779,\n",
       "          0.2015, -0.2394,  0.5490, -0.0945,  0.5477,  0.4221, -0.4798, -0.2160,\n",
       "         -0.2127, -0.1050,  0.5879, -0.5503,  0.0241,  0.6395,  0.5077, -0.3757,\n",
       "         -0.5690, -0.3382,  0.1261,  0.1207, -0.6684, -0.3214, -0.3190, -0.3199,\n",
       "          0.3430, -0.3240, -0.0356, -0.1878, -0.0386,  0.6350,  0.2160,  0.2028,\n",
       "         -0.5308,  0.6351, -0.4861,  0.2971,  0.1888, -0.0777,  0.3958,  0.5448,\n",
       "         -0.7455, -0.1682,  0.2728,  0.0199,  0.1171,  0.7565, -0.2000,  0.0666,\n",
       "          0.0963,  0.2466, -0.4311, -0.4961, -0.0910, -0.7480, -0.0293,  0.4221,\n",
       "         -0.5491, -0.5347,  0.4298,  0.1759, -0.2297, -0.2388, -0.5337, -0.5790,\n",
       "          0.2925,  0.3752, -0.0570, -0.1144,  0.1009, -0.2585,  0.1409, -0.5397,\n",
       "          0.5473,  0.3388,  0.5609, -0.1807,  0.0012,  0.2732,  0.4314, -0.6154,\n",
       "          0.2442,  0.4934, -0.6442, -0.3452,  0.3183, -0.7100,  0.6755, -0.6285,\n",
       "          0.3055, -0.4012,  0.7258,  0.2231, -0.2437,  0.5560, -0.5132, -0.2402,\n",
       "          0.0184, -0.1367,  0.4517, -0.4313, -0.3470, -0.1483,  0.3294, -0.0137,\n",
       "          0.6161,  0.1191, -0.0442,  0.6684, -0.0523,  0.4287, -0.3766, -0.0659,\n",
       "         -0.3901,  0.1979,  0.6623, -0.2596, -0.4443, -0.5377,  0.1772,  0.2564,\n",
       "          0.8487,  0.2412, -0.2758,  0.5257,  0.3792, -0.1704,  0.4779,  0.3171,\n",
       "          0.1120,  0.6001,  0.6845,  0.1721,  0.2787,  0.4553,  0.2696,  0.3487,\n",
       "         -0.7369,  0.0014,  0.6349, -0.3800,  0.0874,  0.0298,  0.3102, -0.0146,\n",
       "         -0.1093, -0.4387,  0.5509, -0.3503,  0.5488, -0.5800, -0.5505,  0.1941,\n",
       "         -0.1639, -0.6729,  0.1945, -0.0928,  0.6247,  0.3783, -0.4021, -0.6739,\n",
       "         -0.2534, -0.0709, -0.5702, -0.5563, -0.2429, -0.5407,  0.2157, -0.0992,\n",
       "         -0.6588, -0.8748, -0.3030,  0.4324,  0.5147,  0.0304,  0.3774, -0.2145,\n",
       "         -0.2499, -0.3578, -0.2196,  0.1990,  0.2335, -0.4632,  0.3198,  0.1159,\n",
       "         -0.4675, -0.6177,  0.4396,  0.3704,  0.1825, -0.1978, -0.2615,  0.4063,\n",
       "         -0.3872,  0.5441, -0.0478, -0.4659,  0.4502,  0.1398,  0.4098, -0.2125,\n",
       "          0.2320, -0.6604, -0.0587,  0.6413,  0.0545,  0.8202, -0.5320,  0.4708,\n",
       "         -0.4421,  0.4540,  0.3508,  0.5891,  0.2586, -0.2838, -0.5624,  0.0018,\n",
       "          0.8198, -0.6805,  0.3023, -0.4865,  0.0216,  0.6397, -0.3134, -0.2803,\n",
       "         -0.6927,  0.1669, -0.3676, -0.2885, -0.1762, -0.6751, -0.1313,  0.1891,\n",
       "         -0.6917,  0.3137,  0.2394,  0.1477, -0.0465,  0.0805, -0.3623,  0.0243,\n",
       "          0.5851, -0.1483,  0.7046,  0.4200,  0.3982,  0.4530, -0.2237, -0.4677,\n",
       "          0.3410,  0.1037,  0.3080, -0.1464, -0.2931,  0.0293, -0.6291,  0.6201,\n",
       "          0.2102,  0.0216, -0.4731, -0.0124, -0.7807, -0.5641, -0.4653, -0.4474,\n",
       "         -0.0048,  0.4275,  0.0966,  0.5359,  0.0645, -0.2992, -0.6987, -0.5048,\n",
       "         -0.5645,  0.3784, -0.0098, -0.1680,  0.1120, -0.1315, -0.5857, -0.4142,\n",
       "          0.0038,  0.5119, -0.6092,  0.0609, -0.2409,  0.7382, -0.1732,  0.2258,\n",
       "          0.7986, -0.6208, -0.3300,  0.2954, -0.3099,  0.3529, -0.4222, -0.6584,\n",
       "         -0.3195, -0.0656,  0.1638,  0.7116,  0.2959,  0.6113,  0.4311, -0.3177,\n",
       "         -0.2373,  0.4840, -0.4757, -0.0459,  0.5237,  0.2445, -0.1210, -0.1020,\n",
       "          0.2188,  0.4206,  0.9081,  0.1675, -0.3298, -0.4039,  0.1037, -0.5654,\n",
       "         -0.3353, -0.1468,  0.0520,  0.1698,  0.2647, -0.2250, -0.7292,  0.3164,\n",
       "          0.6687, -0.0147,  0.3980,  0.7523, -0.4409, -0.0796,  0.7386,  0.3808,\n",
       "          0.2718, -0.4955,  0.7958, -0.3024,  0.6744,  0.0252,  0.0760,  0.6543,\n",
       "          0.0981,  0.7647, -0.3471,  0.1895, -0.1313, -0.4203,  0.2094, -0.3155,\n",
       "          0.3739,  0.0017,  0.1803, -0.3757, -0.2716, -0.7827,  0.5367,  0.0380,\n",
       "         -0.0086,  0.0386, -0.6772, -0.0338,  0.5010,  0.7074,  0.6415, -0.2478,\n",
       "         -0.2474, -0.1483, -0.0211, -0.0761, -0.1804, -0.3266,  0.4240,  0.7357,\n",
       "          0.2750,  0.3023,  0.4035, -0.6735, -0.2029, -0.1713,  0.0825, -0.1998,\n",
       "         -0.5192,  0.1781, -0.5276, -0.2746, -0.0214,  0.3281, -0.4023, -0.0369,\n",
       "          0.1270, -0.6040, -0.0793, -0.4008,  0.3040,  0.5056,  0.2750, -0.2028,\n",
       "         -0.4514, -0.4552,  0.6020,  0.1890, -0.5657, -0.2175, -0.5083, -0.2867,\n",
       "          0.7012, -0.7194,  0.0456,  0.0069, -0.2066, -0.2554, -0.2350, -0.6756,\n",
       "          0.1297, -0.0633, -0.6605,  0.3466,  0.7892, -0.4144,  0.5130, -0.2766,\n",
       "          0.1871, -0.3769,  0.1443, -0.0302, -0.0186,  0.1177,  0.1131, -0.4398,\n",
       "         -0.1252, -0.4525, -0.0334, -0.1505, -0.2116,  0.2202,  0.2090,  0.2044,\n",
       "         -0.1390,  0.3321, -0.2579,  0.1025,  0.0833, -0.1912, -0.3672,  0.6544,\n",
       "         -0.0701,  0.1155, -0.2808, -0.7079, -0.1921,  0.5369,  0.4648, -0.1458,\n",
       "         -0.2510,  0.3618,  0.2791, -0.1345,  0.2311, -0.2619, -0.1802,  0.3352,\n",
       "         -0.2648,  0.6696, -0.2443, -0.2165,  0.5646, -0.0084, -0.2821, -0.3443,\n",
       "          0.5407,  0.6645,  0.3981,  0.4053,  0.3178, -0.0116, -0.5881,  0.1888,\n",
       "          0.2361,  0.4652,  0.3319,  0.2626,  0.1612,  0.6204,  0.1064,  0.0493,\n",
       "         -0.2340, -0.5773,  0.4343, -0.6271,  0.5380,  0.6907,  0.3017, -0.6289,\n",
       "          0.4238, -0.3234, -0.2629,  0.0668, -0.1855,  0.6327, -0.6949, -0.4140,\n",
       "          0.1934,  0.8718,  0.1490,  0.4594, -0.1362, -0.8291,  0.5334, -0.2294,\n",
       "          0.3580,  0.2720, -0.2792, -0.3625, -0.4040, -0.1224, -0.3223,  0.1839,\n",
       "         -0.6301,  0.7348, -0.1644, -0.0799,  0.1521,  0.2131,  0.2926,  0.4979,\n",
       "         -0.7100,  0.7634, -0.3106, -0.5746, -0.2020,  0.1729,  0.0143, -0.2720,\n",
       "         -0.7822,  0.3757, -0.5716,  0.3509,  0.4403, -0.0924, -0.2935, -0.6458,\n",
       "          0.6012,  0.4953, -0.3643, -0.0983,  0.7736,  0.1942,  0.2940,  0.4651,\n",
       "         -0.6030,  0.4058, -0.0214,  0.4324, -0.1110, -0.0874,  0.0112, -0.7064,\n",
       "         -0.5217,  0.1523,  0.1940, -0.0130,  0.3491, -0.2087,  0.2800, -0.5133,\n",
       "         -0.0322,  0.4119, -0.2256, -0.0440, -0.6331,  0.0359, -0.2215, -0.4995,\n",
       "          0.2356,  0.3098,  0.7765, -0.2564, -0.2825, -0.4071, -0.3193,  0.4955,\n",
       "          0.5417, -0.1415, -0.5696, -0.2017,  0.1464,  0.0636,  0.2927, -0.6502,\n",
       "         -0.4364,  0.1255,  0.8233,  0.3629,  0.2609, -0.1263, -0.5645,  0.4241,\n",
       "          0.3714, -0.7563, -0.1817,  0.5886,  0.6322, -0.2679,  0.3980, -0.3155,\n",
       "         -0.3204,  0.2672,  0.5431,  0.5502,  0.5136, -0.1727, -0.2185, -0.7589,\n",
       "         -0.6092, -0.8298,  0.8129,  0.2080,  0.1520,  0.1092, -0.4730,  0.6383,\n",
       "         -0.2543,  0.8968,  0.0295,  0.3473, -0.4490,  0.5396, -0.0492, -0.6604]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_tensor = torch.randn(1, 3, 224, 224)\n",
    "create_model()(in_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare an image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "#Import image augmentation clases from torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize, RandomHorizontalFlip, RandomRotation, Resize\n",
    "from torch.utils.data import DataLoader\n",
    "image_path = './data/eurosat'\n",
    "transform = Compose([\n",
    "    #Resize to 224\n",
    "    Resize(224),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomRotation(degrees=10),\n",
    "    ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "eurosat_dataset = datasets.EuroSAT(root=image_path, transform=transform, download=True)\n",
    "\n",
    "#Randomize the dataset\n",
    "torch.manual_seed(1)\n",
    "train_len = int(0.85 * len(eurosat_dataset)) - int(0.85 * len(eurosat_dataset) * 0.2)\n",
    "valid_len = int(0.85 * len(eurosat_dataset) * 0.2)\n",
    "test_len = len(eurosat_dataset) - train_len - valid_len\n",
    "train_dataset, test_dataset, valid_dataset = torch.utils.data.random_split(eurosat_dataset, [train_len, valid_len, test_len])\n",
    "\n",
    "#Create DataLoaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=20)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=20)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create the training loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, train_dl, valid_dl, gpu=False):\n",
    "    if gpu:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_hist_train = [0] * epochs\n",
    "    accuracy_hist_train = [0] * epochs\n",
    "\n",
    "    loss_hist_valid = [0] * epochs\n",
    "    accuracy_hist_valid = [0] * epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            if gpu:\n",
    "                x_batch = x_batch.cuda()\n",
    "                y_batch = y_batch.cuda()\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            \n",
    "            loss.backward() #Calculate tensor gradients with backpropagation\n",
    "            optimizer.step() #Apply updates to weights using the optimizer gradient descent specif impl algorithm\n",
    "            optimizer.zero_grad() #Reset the gradients for the next iteration\n",
    "            \n",
    "            #Calculate and save matrics\n",
    "            loss_hist_train[epoch] += loss.item() * y_batch.size(0) #Add the loss to the loss history\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).cpu().float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "\n",
    "        loss_hist_train[epoch] /= train_len\n",
    "        accuracy_hist_train[epoch] /= train_len\n",
    "\n",
    "        model.eval() #Set the model to evaluation mode\n",
    "        with torch.no_grad(): #Turn off gradients\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                if gpu:\n",
    "                    x_batch = x_batch.cuda()\n",
    "                    y_batch = y_batch.cuda()\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += (loss.item() * y_batch.size(0))\n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).cpu().float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "            loss_hist_valid[epoch] /= valid_len\n",
    "            accuracy_hist_valid[epoch] /= valid_len\n",
    "        print(f'Epoch {epoch+1}/{epochs} accuracy: {accuracy_hist_train[epoch]:4f} valid_accuracy: {accuracy_hist_valid[epoch]:4f}')\n",
    "    return loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, gpu=False):\n",
    "    if gpu:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()    \n",
    "    model.eval()\n",
    "    y_list = []\n",
    "    pred_list = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        if gpu:\n",
    "            x_batch = x_batch.cuda()\n",
    "        pred = model(x_batch)\n",
    "        pred_list.append(torch.argmax(pred, dim=1).cpu())\n",
    "        y_list.append(y_batch)\n",
    "    preds = torch.cat(pred_list, dim=0)\n",
    "    y_true = torch.cat(y_list, dim=0)    \n",
    "    #Calculate the accuracy\n",
    "    is_correct = (preds == y_true).float()\n",
    "    accuracy = is_correct.sum() / is_correct.numel()\n",
    "    print(f'Accuracy: {accuracy:4f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 accuracy: 0.341340 valid_accuracy: 0.435076\n",
      "Epoch 2/40 accuracy: 0.596786 valid_accuracy: 0.590850\n",
      "Epoch 3/40 accuracy: 0.679684 valid_accuracy: 0.578867\n",
      "Epoch 4/40 accuracy: 0.716558 valid_accuracy: 0.663834\n",
      "Epoch 5/40 accuracy: 0.734586 valid_accuracy: 0.643137\n",
      "Epoch 6/40 accuracy: 0.759749 valid_accuracy: 0.638344\n",
      "Epoch 7/40 accuracy: 0.775327 valid_accuracy: 0.671242\n",
      "Epoch 8/40 accuracy: 0.788344 valid_accuracy: 0.705229\n",
      "Epoch 9/40 accuracy: 0.783660 valid_accuracy: 0.692810\n",
      "Epoch 10/40 accuracy: 0.809205 valid_accuracy: 0.699129\n",
      "Epoch 11/40 accuracy: 0.825654 valid_accuracy: 0.751634\n",
      "Epoch 12/40 accuracy: 0.841285 valid_accuracy: 0.716993\n",
      "Epoch 13/40 accuracy: 0.841122 valid_accuracy: 0.734858\n",
      "Epoch 14/40 accuracy: 0.844009 valid_accuracy: 0.758388\n",
      "Epoch 15/40 accuracy: 0.860621 valid_accuracy: 0.757734\n",
      "Epoch 16/40 accuracy: 0.858987 valid_accuracy: 0.763399\n",
      "Epoch 17/40 accuracy: 0.863344 valid_accuracy: 0.749455\n",
      "Epoch 18/40 accuracy: 0.869771 valid_accuracy: 0.762527\n",
      "Epoch 19/40 accuracy: 0.886057 valid_accuracy: 0.784096\n",
      "Epoch 20/40 accuracy: 0.885621 valid_accuracy: 0.777342\n",
      "Epoch 21/40 accuracy: 0.891176 valid_accuracy: 0.786492\n",
      "Epoch 22/40 accuracy: 0.893028 valid_accuracy: 0.749891\n",
      "Epoch 23/40 accuracy: 0.893627 valid_accuracy: 0.755556\n",
      "Epoch 24/40 accuracy: 0.898638 valid_accuracy: 0.750980\n",
      "Epoch 25/40 accuracy: 0.905120 valid_accuracy: 0.786274\n",
      "Epoch 26/40 accuracy: 0.908007 valid_accuracy: 0.793900\n",
      "Epoch 27/40 accuracy: 0.909913 valid_accuracy: 0.793900\n",
      "Epoch 28/40 accuracy: 0.908061 valid_accuracy: 0.784314\n",
      "Epoch 29/40 accuracy: 0.904902 valid_accuracy: 0.778431\n",
      "Epoch 30/40 accuracy: 0.923529 valid_accuracy: 0.787364\n",
      "Epoch 31/40 accuracy: 0.915904 valid_accuracy: 0.774728\n",
      "Epoch 32/40 accuracy: 0.917048 valid_accuracy: 0.784314\n",
      "Epoch 33/40 accuracy: 0.925054 valid_accuracy: 0.770588\n",
      "Epoch 34/40 accuracy: 0.924564 valid_accuracy: 0.784532\n",
      "Epoch 35/40 accuracy: 0.921950 valid_accuracy: 0.780828\n",
      "Epoch 36/40 accuracy: 0.928050 valid_accuracy: 0.788671\n",
      "Epoch 37/40 accuracy: 0.932843 valid_accuracy: 0.799129\n",
      "Epoch 38/40 accuracy: 0.919662 valid_accuracy: 0.783660\n",
      "Epoch 39/40 accuracy: 0.922658 valid_accuracy: 0.786928\n",
      "Epoch 40/40 accuracy: 0.936492 valid_accuracy: 0.791068\n",
      "Time to train: 104.68089032173157\n"
     ]
    }
   ],
   "source": [
    "gpu_model = create_model()\n",
    "\n",
    "#Measure the time it takes to train the model\n",
    "import time\n",
    "start = time.time()\n",
    "loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid = train(gpu_model, epochs=40, train_dl=train_loader, valid_dl=valid_loader, gpu=True)\n",
    "end = time.time()\n",
    "print(f'Time to train: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 accuracy: 0.351144 valid_accuracy: 0.488671\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid \u001b[39m=\u001b[39m train(cpu_model, epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, train_dl\u001b[39m=\u001b[39;49mtrain_loader, valid_dl\u001b[39m=\u001b[39;49mvalid_loader, gpu\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTime to train: \u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m-\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, train_dl, valid_dl, gpu)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m pred \u001b[39m=\u001b[39m model(x_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y_batch)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m#Calculate tensor gradients with backpropagation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m#Apply updates to weights using the optimizer gradient descent specif impl algorithm\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/Projects/machine-learning-samples/pytorch_cnn_cls_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m#Reset the gradients for the next iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cpu_model = create_model()\n",
    "\n",
    "#Measure the time it takes to train the model\n",
    "import time\n",
    "start = time.time()\n",
    "loss_hist_train, accuracy_hist_train, loss_hist_valid, accuracy_hist_valid = train(cpu_model, epochs=15, train_dl=train_loader, valid_dl=valid_loader, gpu=False)\n",
    "end = time.time()\n",
    "print(f'Time to train: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plot the loss\n",
    "plt.plot(loss_hist_train, label='Training Loss')\n",
    "plt.plot(loss_hist_valid, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.896732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8967)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(gpu_model, test_loader, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model(cpu_model, test_loader, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "class ClsModel(pl.LightningModule):\n",
    "    def __init__(self, img_channels=3) -> None:\n",
    "        super().__init__()\n",
    "        model = nn.Sequential()\n",
    "        model.add_module('conv0', nn.Conv2d(in_channels=img_channels, out_channels=16, kernel_size=5, padding='same'))\n",
    "        model.add_module('relu0', nn.ReLU())\n",
    "        model.add_module('pool0', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        model.add_module('conv1', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding='same'))\n",
    "        model.add_module('relu1', nn.ReLU())\n",
    "        model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same'))\n",
    "        model.add_module('relu2', nn.ReLU())\n",
    "        model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
    "        \n",
    "\n",
    "        model.add_module('flatten', nn.Flatten())\n",
    "        model.add_module('ln0', nn.Linear(4096, out_features=1024))\n",
    "        model.add_module('relu4', nn.ReLU())\n",
    "        model.add_module('ln1', nn.Linear(1024, out_features=10))\n",
    "        self.model = model\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def step(self, batch):\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        return loss_fn(y_pred, y)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss = self.step(train_batch)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss  \n",
    "\n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        loss = self.step(valid_batch)\n",
    "        self.log('valid_loss', loss)\n",
    "        return loss       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 4.3 M \n",
      "-------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.084    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60394c98cf8241379c1af6b4166c2218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63d775804c041cfb1b35daa774a2a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8185c3a0a4924e5d8748cc57944470d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c02f7f3bbac478da18d323736bcd60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d007a7cfe17a45e98aab92dd8332b673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f102087850924624b02fb9b0f9663d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2f27ee7160462da9fc5e741cac4501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a538159dd4b0427aa9157b032c2035bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe2520a38874ff7aa8743fb9b573679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862372735be64b5eacb5a11f74edc04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6696e39f8ee4a60b0de7b9c3f91e7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0618d8ab1a7490ba89ed7f7c33d41b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98392991ae3b4f7f8d9d4570da539f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b395b5ccd4c94b8d96274d42f3220a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d9cf357ef84408b9c0dc78cc1d8bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6212a67653441282f9577480c9a0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3936890471cb4678871f247391af06d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ac75579d8f407dbbca6c155fe4d5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ed9a455e6b4bfeae0c3e041227b936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffe47f85c864d7b8030263dd99d979b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7544a068f6243f4ad919d96724cb9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabb611a0baf46659aab4eb110764329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 58.0283567905426\n"
     ]
    }
   ],
   "source": [
    "lmodel = ClsModel()\n",
    "trainer = pl.Trainer(max_epochs=20, accelerator='gpu', devices=1)\n",
    "\n",
    "start = time.time()\n",
    "trainer.fit(lmodel, train_loader, valid_loader)\n",
    "end = time.time()\n",
    "print(f'Time to train: {end-start}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8196)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(lmodel, test_loader, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('transformers')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "67eaa3341532a776c118222830d768cadfe50256155e6c2909c4d9b554175a76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
