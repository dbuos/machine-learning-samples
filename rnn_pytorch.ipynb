{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using torchtext datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "train_ds = IMDB('./data/imdb/train', split='train')\n",
    "train_ds = list(train_ds)\n",
    "\n",
    "test_ds = IMDB('./data/imdb/test', split='test')\n",
    "test_dataset = list(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "train_dataset, valid_dataset = random_split(train_ds, [20000, 5000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 69367\n"
     ]
    }
   ],
   "source": [
    "from text_tokenizer import build_vocab\n",
    "token_counts = build_vocab(train_dataset)\n",
    "vocab_size = len(token_counts)\n",
    "print('vocab_size:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the encoding dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import OrderedDict\n",
    "sorted_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "tokens_dict = OrderedDict(sorted_tokens)\n",
    "text_vocab = vocab(tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocab.insert_token('<pad>', 0)\n",
    "text_vocab.insert_token('<unk>', 1)\n",
    "text_vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_tokenizer import tokenizer\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def text_pipeline(text):\n",
    "    return [text_vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "def label_pipeline(label):\n",
    "    return 1. if label == 'pos' else 0.\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels, texts, texts_lenghts = [], [], []\n",
    "    for label, text in batch:\n",
    "        labels.append(label_pipeline(label))\n",
    "        procesed_text = text_pipeline(text)\n",
    "        texts.append(torch.tensor(procesed_text, dtype=torch.int32))\n",
    "        texts_lenghts.append(len(procesed_text))\n",
    "    labels = torch.tensor(labels)\n",
    "    texts_lenghts = torch.tensor(texts_lenghts)\n",
    "    texts = pad_sequence(texts, batch_first=True)    \n",
    "    return texts, labels, texts_lenghts   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch, num_workers=20)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch, num_workers=20)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 62, 8])\n",
      "torch.Size([1, 32, 8])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "features_size = 30\n",
    "batch_size = 32\n",
    "sequences_len = 62\n",
    "rnn = nn.RNN(input_size=features_size, hidden_size=8, num_layers=1, batch_first=True)\n",
    "sample_batch = torch.rand(batch_size, sequences_len, features_size)\n",
    "a, b = rnn(sample_batch)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "\n",
    "lstm = nn.LSTM(input_size=features_size, hidden_size=8, num_layers=1, batch_first=True)\n",
    "c, d = lstm(sample_batch)\n",
    "print(type(c))\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 127,   13,  249,  ...,    0,    0,    0],\n",
       "         [  35,  301,  240,  ...,    0,    0,    0],\n",
       "         [  11,   65,  143,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [  10,   65,  507,  ...,    0,    0,    0],\n",
       "         [   2, 1088,    5,  ...,    0,    0,    0],\n",
       "         [   2,   20,    7,  ...,    0,    0,    0]], dtype=torch.int32),\n",
       " tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 0., 1., 0., 1.]),\n",
       " tensor([176, 322, 183, 110, 505, 381, 127, 168, 212, 178, 657, 207, 149, 119,\n",
       "         174, 255, 104, 168, 105, 249, 122, 156,  90,  95, 293, 225, 309, 307,\n",
       "          78, 201, 403,  81, 211, 526, 131, 147, 305, 363, 129, 135, 171, 288,\n",
       "         167, 254, 134, 263, 529, 530, 162, 157, 157, 194, 285,  65, 460, 157,\n",
       "         163, 323, 180, 925,  74, 195, 452, 129]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_size = 16\n",
    "vocab_size = len(token_counts)\n",
    "emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=features_size, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentModel0(\n",
      "  (emb): Embedding(69369, 20, padding_idx=0)\n",
      "  (rnn): LSTM(20, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc_relu): ReLU()\n",
      "  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SentimentModel0(nn.Module):\n",
    "    def __init__(self, vocab_size, features_size=20, hidden_size=64, fc_size=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=features_size, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(input_size=features_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, fc_size)\n",
    "        self.fc_relu = nn.ReLU()\n",
    "        self.fc_out = nn.Linear(fc_size, 1)\n",
    "\n",
    "    def forward(self, texts, texts_lengths):\n",
    "        out = self.emb(texts)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, texts_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = self.fc_relu(out)\n",
    "        out = self.fc_out(out)\n",
    "        return out    \n",
    "\n",
    "model = SentimentModel0(vocab_size+2)\n",
    "print(model)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, device, loss_fn, progress_bar):\n",
    "    model.train()\n",
    "    epoch_loss, epoch_acc = 0., 0.\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    for text_batch, labels_batch, lengths_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        text_batch = text_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        lengths_batch = lengths_batch.to(device)\n",
    "        y_pred = model(text_batch, lengths_batch)[:, 0]\n",
    "        loss = loss_fn(y_pred, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update(1)\n",
    "        epoch_loss += loss.item() * text_batch.size(0)\n",
    "        epoch_acc += (torch.sigmoid(y_pred).round() == labels_batch).float().sum().item()\n",
    "    return epoch_acc/num_samples, epoch_loss/num_samples    \n",
    "        \n",
    "        \n",
    "def evaluate(model, dataloader, device, loss_fn):\n",
    "    model.eval()\n",
    "    epoch_loss, epoch_acc = 0., 0.\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for text_batch, labels_batch, lengths_batch in dataloader:\n",
    "            text_batch = text_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "            lengths_batch = lengths_batch.to(device)\n",
    "            y_pred = model(text_batch, lengths_batch)[:, 0]\n",
    "            loss = loss_fn(y_pred, labels_batch)\n",
    "            epoch_loss += loss.item() * text_batch.size(0)\n",
    "            epoch_acc += (torch.sigmoid(y_pred).round() == labels_batch).float().sum().item()\n",
    "    return epoch_acc/num_samples, epoch_loss/num_samples   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c4c2ac62844a78a08fb85876cc2a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.1234, Train Acc: 0.9582, Valid Loss: 0.3727, Valid Acc: 0.8738\n",
      "Epoch: 1, Train Loss: 0.0986, Train Acc: 0.9679, Valid Loss: 0.4003, Valid Acc: 0.8750\n",
      "Epoch: 2, Train Loss: 0.0811, Train Acc: 0.9750, Valid Loss: 0.4324, Valid Acc: 0.8724\n",
      "Epoch: 3, Train Loss: 0.0679, Train Acc: 0.9796, Valid Loss: 0.4846, Valid Acc: 0.8698\n",
      "Epoch: 4, Train Loss: 0.0504, Train Acc: 0.9862, Valid Loss: 0.5121, Valid Acc: 0.8744\n",
      "Epoch: 5, Train Loss: 0.0394, Train Acc: 0.9891, Valid Loss: 0.5614, Valid Acc: 0.8666\n",
      "Epoch: 6, Train Loss: 0.0301, Train Acc: 0.9922, Valid Loss: 0.5898, Valid Acc: 0.8714\n",
      "Epoch: 7, Train Loss: 0.0248, Train Acc: 0.9937, Valid Loss: 0.6181, Valid Acc: 0.8700\n",
      "Epoch: 8, Train Loss: 0.0178, Train Acc: 0.9959, Valid Loss: 0.7040, Valid Acc: 0.8678\n",
      "Epoch: 9, Train Loss: 0.0105, Train Acc: 0.9980, Valid Loss: 0.6920, Valid Acc: 0.8678\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "epochs = 10\n",
    "progress_bar = tqdm(range(epochs*len(train_dataloader)))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc, train_loss = train(model, train_dataloader, optimizer, device, loss_fn, progress_bar)\n",
    "    valid_acc, valid_loss = evaluate(model, valid_dataloader, device, loss_fn)\n",
    "    print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cdbf094c3e2d11b30478a1f6f10290d4ee78e6b46f57992373b88ecd109df83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
